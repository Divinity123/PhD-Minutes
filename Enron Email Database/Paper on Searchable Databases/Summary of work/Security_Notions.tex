In this section, we discuss why previous notions are not sufficient in defining security of searchable encryption schemes. We then motivates with a security notion for keyword guessing attack on searchable encrypted databases. We modify the experiment by considering a leakage function instead of the real encryption function. After that, we generalise the experiment to allow for arbitrary adversarial goals.



\subsection{Previous Notions}
Several security notions have been proposed in the literature. The first notion is based on an indistinguishability game which tries to capture the idea that the encrypted index does not leak any information about the underlying files. The notion is known as indistinguishability under chosen keyword attack (IND-CKA) is proposed by Goh in \cite{EPRINT:Goh03}. A slightly stronger notion known as IND2-CKA has been proposed later in the same paper. However this notion is not sufficient because it only captures security of encrypted database and does not consider interaction between client and server via queries. Curtmola et al. \cite{CCS:CGKO06} improved on the notion and proposed non-adaptive indistinguishability security and adaptive indistinguishability security for searchable symmetric encryption (SSE). The most remarkable difference between Curtmola's notion and Goh's is that the trace\footnote{Trace is defined to be the collection of document sizes, search pattern and access pattern.} of database is allowed to be leaked. The authors have also defined simulator-based security notions and proved equivalence of those to the indistinguishability-based notions. The idea of allowing some leakage is then generalised to be beyond just the trace \cite{AC:ChaKam10, C:CJJKRS13, NDSS:StePapShi14,ESORICS:FJKNRS15}. 

However, security with leakage does not imply security in practice. One needs to understand what those leakages really reveals about the underlying database. In some cases, that is obvious. For example, if the leakage function is everything of the database then we know the encryption scheme is not secure, and if the leakage function reveals nothing then the scheme is secure. But with anything in between, we are not able to draw conclusion immediately. In fact, many types of leakages can be abused to recover information about the underlying database. If a scheme leaks repetition of keywords then it may be vulnerable to frequency-based statistical attack \cite{CCS:NavKamWri15}. If a scheme leaks co-occurrence of keywords then it can be exploited by IKK attack \cite{NDSS:IslKuzKan12} and count attack \cite{CCS:CGPR15}. Notably, co-occurrence is part of search pattern and access pattern and those are leaked by most of the schemes. More complicated leakage pattern involving bloom filter can also be misused \cite{CCS:PouWri16}. Therefore, in order to prove that a scheme is secure for practical use, we have to show that the leakage does not reveal information of the underlying database we try to hide.

The first step towards this goal is to consider a snapshot adversary who only has access to the encrypted database in the static manner and tries to recover some information. To make it more concrete, we consider an adversary who tries to recover some encrypted keywords. We call the security notion security against keyword guessing attack.




\subsection{Security Notion for Keyword Guessing Attack}
There is a multitude of ways to evaluate how well the adversary has recovered information through keyword guessing attack. We will present with one of the simplest here. Namely, the adversary wins if he recovers a correct pair of keyword and its encryption (with one guess).

For simplicity, we consider snapshot attack here so the adversary is given the leakage of the scheme and there is no interaction between the encrypted database and the adversary. We may abuse $\dec(\cdot)$ to be the function that decrypts an encrypted document or a set of encrypted keywords associated to an encrypted document, and outputs the set of real keywords.

\begin{definition}[Security against Keyword Guessing Attack] \label{Security against Keyword Guessing Attack}
We define a keyword guessing attack adversary to be $\mathcal{A} = (\mathcal{A}_0, \mathcal{A}_1)$, where $\mathcal{A}_0$ is a probabilistic polynomial time (PPT) adversary which takes in the security parameter and generates a state $\state$ and a database $\db$, and $\mathcal{A}_1$ is a PPT adversary which takes in the security parameter, state $\state$ and encrypted database $\edb$, and returns a pair of keyword and encrypted keyword. The experiment can be described as follows:

\begin{pchstack}[center]
	\procedure{Exp$_{\adv}^{\text{Keyword-Guessing}}(n)$}{%
		\pcln \key \sample \kgen(\secparam) \\
		\pcln (\state, \db)  \gets \mathcal{A}_0(\secparam) \\
		\pcln \edb \gets \enc(\secparam, \key, \db) \\
		\pcln (m, c) \gets \mathcal{A}_1(\secparam, \state, \edb) \\
		\pcln \pcif (m \in \KWset(\db)) \wedge (c \in \EKWset(\edb)) \wedge (\dec(c) = m) \\
		\pcln \pcind \pcreturn 1 - f(m, \db) \\
		\pcln \pcelse \pcreturn - f(m, \db)
	}
\end{pchstack}
where $f(m, \db)$ is a function that returns the frequency of keyword $m$ in database $\db$.

Advantage $\advantage_{\mathcal{A}}^{\text{Keyword-Guessing}}(n)$ of an inference attack adversary $\mathcal{A}$ is defined to be
\begin{equation}
	\advantage_{\mathcal{A}}^{\text{Keyword-Guessing}}(n) = \expect{\text{Exp}_{\adv}^{\text{Keyword-Guessing}}(n)}.
\end{equation}
We say that a scheme is secure against keyword guessing attack if $\advantage_{\mathcal{A}}^{\text{Keyword-Guessing}}(n)$ is less than some negligible function in $n$.
\end{definition}


Intuitively, a scheme is secure against keyword guessing attack if there is no way he can guess any plaintext-ciphertext pair with probability greater than the frequency of the plaintexts. There are other possible definitions, for instance, one can look at the probability the adversary guessing all pairs of plaintexts and ciphertexts correctly.

This security notion is hard to work with because the database the adversary can generate is literally anything and the encryption scheme can generate any ciphertext. But in our game, we really do not care if keywords are `1' and `2' or `one' and `two', nor do we care how the ciphertexts look like. To simplify the problem, we want to work with idealised databases and encryption schemes which allows us to ignore information that are not relevant to our security game. Due to necessity of efficient searchability, encryption schemes for searchable encryption cannot achieve IND-CPA security, and the `insecure part' of encryption function (and query functions) are understood in terms of leakage functions. Informally speaking, leakage function associated to a scheme captures what is leaked about the unencrypted database by looking at its encryption. For example, number of documents is part of leakage for any scheme that does not pad fake documents because after enough queries, all documents will be returned at least once, unless part of the database is never going to be returned by any query, but that defeats the purpose of putting them there in the first place.

In the next experiment, the adversary is only given the leakage associated to the mechanism applied to the generated database. We argue that by choosing the leakage carefully, the advantage for the experiment will be the same as the previous one, up to an additive negligible term. We begin by defining leakage of searchable encryption.


\begin{definition}[Leakage of Encryption Schemes for Searching]
Let $\enc$ be the encryption algorithm for some searchable encryption scheme. We say $\leakm: \db \times \Key \rightarrow \{0,1\}^{*}$ is a valid leakage function for the mechanism if for all adversaries $\mathcal{A}$ there exists a simulator $\mathcal{S}$ such that for any PPT distinguishers $\mathcal{D}$, the following two games are indistinguishable.
	
\begin{pchstack}[center]
\procedure{Real$_{\mathcal{A}}(n)$}{%
	\pcln \key \sample \kgen(\secparam) \\
	\pcln \db  \gets \mathcal{A}(\secparam) \\
	\pcln \edb \gets \enc(\secparam, \key, \db) \\
	\pcln \pcreturn \edb
}	

\pchspace
\procedure{Sim$_{\mathcal{A,S}}(n)$}{%
	\pcln \key  \sample \kgen(\secparam) \\
	\pcln \db   \gets \mathcal{A}(\secparam) \\
	\pcln \leak \gets \leakm(\secparam, \key, \db) \\
	\pcln \edb  \gets \mathcal{S}(\secparam, \leak) \\
	\pcln \pcreturn \edb
}
\end{pchstack}

$\leakm$ is said to be minimal if there exists a simulator $\mathcal{S}$ such that for all adversaries $\mathcal{A}$, no PPT distinguishers $\mathcal{D}$ can distinguish the two games above.
\end{definition}


Now we are ready to define security against idealised keyword guessing attack.


\begin{definition}[Security against Idealised Keyword Guessing Attack]
We define an idealised keyword guessing attack adversary to be $\mathcal{A} = (\mathcal{A}_0, \mathcal{A}_1)$, where $\mathcal{A}_0$ is a PPT adversary which takes in the security parameter and generates a state $\state$ and a database $\db$, and $\mathcal{A}_1$ is any adversary (not necessarily polynomial time bounded) which takes in the security parameter, state $\state$ and leakage $\leak$ generated by the minimal leakage function $\leakm$, and returns a pair of keyword and encrypted keyword. The experiment can be described as follows:
\begin{pchstack}[center]
	\procedure{Exp$_{\adv}^{\text{Keyword-Guessing-Ideal}}(n)$}{%
		\pcln \key \sample \kgen(\secparam) \\
		\pcln (\state, \db)  \gets \mathcal{A}_0(\secparam) \\
		\pcln \leak \gets \leakm(\secparam, \key, \db) \\
		\pcln (m, c) \gets \mathcal{A}_1(\secparam, \state, \leak) \\
		\pcln \pcif (m \in \KWset(\db)) \wedge (c \in \EKWset(\edb)) \wedge (\dec(c) = m) \\
		\pcln \pcind \pcreturn 1 - f(m, \db) \\
		\pcln \pcelse \pcreturn - f(m, \db)
	}
\end{pchstack}
where $f(m, \db)$ is a function that returns the frequency of keyword $m$ in database $\db$.

Advantage $\advantage_{\mathcal{A}}^{\text{Keyword-Guessing-Ideal}}(n)$ of an idealised inference attack adversary $\mathcal{A}$ is defined to be
\begin{equation}
\advantage_{\mathcal{A}}^{\text{Keyword-Guessing-Ideal}}(n) = \expect{\text{Exp}_{\adv}^{\text{Keyword-Guessing-Ideal}}(n)}.
\end{equation}
We say that a scheme is secure against idealised keyword guessing attack if $\advantage_{\mathcal{A}}^{\text{Keyword-Guessing-Ideal}}(n)$ is less than some negligible function in $n$.
\end{definition}

Notice that in the definition, $\mathcal{A}_1$ does not need to be PT bounded. This is because we are in the idealised world where the cryptographic part has already been dealt with in the leakage. We will see later that with a well-defined leakage function $\leakm$, advantage of the idealised experiment can be used to upper bound that of the real experiment.




\subsection{Moving from Fixed Target Function to Generic Gain Function}
In the two games for keyword guessing attack we defined above, the content returned by the games are fixed so proving security with respect to the games only says the scheme is secure against this specific adversary who tries to recover this specific information. This is very inflexible as a security notion for application in searchable encryption. In addition, wrong guesses in these games are completely punished in this setting in the sense that they will never show up in the advantage term, even though wrong guesses can still reveal some information. Consider the case where the adversary always tries to guess decryption of some ciphertext $c$ and he always fails because his guess is some $m$ such that $\dec(c) \neq m$. But ultimately, the goal of the adversary can be to recover some keywords in some documents. If $m$ always appears together with $\dec(c)$ in all documents, then in fact, the adversary recovers a significant amount of information about the underlying database, even though the guess itself is wrong. So we need to reward those guesses that are not completely correct but still reveals information about the database appropriately.

To do so, we use idea of gain function from g-leakage paper \cite{6266165}. To put it in simple words, instead returning something from the experiment and analyse it in the advantage term, we compute the gain at the end of the experiment, and the advantage is defined to be the expectation of the result of the experiment for the best adversary. We now define the games with gain functions.


\begin{definition}[Real Game with Gain Function]
We define a real adversary with gain function $g$ to be $\mathcal{A} = (\mathcal{A}_0, \mathcal{A}_1)$, where $\mathcal{A}_0$ is a PPT adversary which takes in the security parameter and generates a database $\db$, and $\mathcal{A}_1$ is a PPT adversary which takes in the security parameter, and encrypted database $\edb$, and returns some guess $w$ in the set of allowed guesses $\W$. The experiment can be described as follows:
\begin{pchstack}[center]
\procedure{Real$_{\adv}^{\ g}(n)$}{%
	\pcln \key \sample \kgen(\secparam) \\
	\pcln \db  \gets \mathcal{A}_0(\secparam) \\
	\pcln \edb \gets \enc(\secparam, \key, \db) \\
	\pcln w \gets \mathcal{A}_1(\secparam, \edb) \\
	\pcln \pcreturn g(w, (\db, \key), \edb)
}
\end{pchstack}

Advantage $\advantage_{\mathcal{A},g}^{\text{Real}}(n)$ is defined to be:
\begin{equation}
	\advantage_{\mathcal{A},g}^{\text{Real}}(n) = \expect{\text{Real}_{\adv}^{\ g}(n)}.
\end{equation}
\end{definition}


\begin{definition}[Ideal Game with Gain Function]
We define an ideal adversary with gain function $g$ to be $\mathcal{A} = (\mathcal{A}_0, \mathcal{A}_1)$, where $\mathcal{A}_0$ is a PPT adversary which takes in the security parameter and generates a database $\db$, and $\mathcal{A}_1$ is an adversary which takes in the security parameter, and a valid leakage function $\leakm$, and returns some guess $w$ in the set of allowed guesses $\W$. The experiment can be described as follows:
\begin{pchstack}[center]
\procedure{Ideal$_{\adv}^{\ \leakm, g}(n)$}{%
	\pcln \key \sample \kgen(\secparam) \\
	\pcln \db  \gets \mathcal{A}_0(\secparam) \\
	\pcln \leak \gets \leakm(\secparam, \key, \db) \\
	\pcln w \gets \mathcal{A}_1(\secparam, \leak) \\
	\pcln \pcreturn g(w, (\db, \key), \leak)
}
\end{pchstack}
	
Advantage $\advantage_{\mathcal{A}, \leakm, g}^{\text{Ideal}}(n)$ is defined to be:
\begin{equation}
	\advantage_{\mathcal{A}, \leakm, g}^{\text{Ideal}}(n) = \expect{\text{Ideal}_{\adv}^{\ \leakm, g}(n)}.
\end{equation}
\end{definition}

Note that we are not putting any condition to quantify when a scheme is secure under these notions, because the advantage really depends on the choice of $g$. But with well-defined $g$, the advantage will have an operational meaning and we can understand the level of security offered by our scheme from there.




\subsection{Games with Gain Function are equivalent to some Extended Posterior g-vulnerability}
In this subsection, we prove that in fact, we can look at the advantage from the games or some corresponding extended posterior g-vulnerability exchangeably. To do so, we need a slight tweak to the games above.

Let $\pi$ be the prior on the joint distribution of databases and keys. Then the games above is equivalent to the following.
\begin{pchstack}[center]
\procedure{Real$_{\adv}^{\ \pi,g}(n)$}{%
	\pcln (\db, \key) \sample \pi \\
	\pcln \edb \gets \enc(\secparam, \key, \db) \\
	\pcln w \gets \mathcal{A}_1(\secparam, \edb) \\
	\pcln \pcreturn g(w, (\db, \key), \edb)
}

\pchspace
\procedure{Ideal$_{\adv}^{\ \pi, \leakm,g}(n)$}{%
	\pcln (\db, \key) \sample \pi \\
	\pcln \leak \gets \leakm(\secparam, \key, \db) \\
	\pcln w \gets \mathcal{A}_1(\secparam, \leak) \\
	\pcln \pcreturn g(w, (\db, \key), \leak)
}
\end{pchstack}


\begin{theorem}[Ideal game is equivalent to an extended posterior g-vulnerability]
	Let $\pi$ be the prior distribution of databases and keys. Let $\X = \DB \times \Key$. Let $\leakm$ be a valid leakage function. Let $\Y = \{\leakm(\secparam, \key, \db) \mid \key \in \Key, \db \in \DB \}$. Let $\channelm$ be the channel matrix from $\X$ to $\Y$. Let $g: \W \times \X \times \Y \rightarrow [0,1]$. Then
	\begin{equation}
	\sup_{\pi \in \text{Dist}} \ \sup_{\mathcal{A}} \advantage_{\mathcal{A}, \pi, \leakm, g}^{\text{Ideal}}(n) = EV_g(\pi, \channelm).
	\end{equation}
	where $Dist$ is the set of valid prior for the database.
\end{theorem}


\begin{proof} 
For simplicity, we assume $Dist$ is a point distribution. So it suffices to look at the expression $\sup_{\mathcal{A}} \advantage_{\mathcal{A}, \pi, \leakm, g}^{\text{Real}}(n)$ with $\leakm$ being a valid leakage. Suppose $\leakm$ is indeed a valid leakage, then
\begin{align}
  & \sup_{\mathcal{A}} \advantage_{\mathcal{A}, \pi, \leakm, g}^{\text{Ideal}}(n) \\
= &	\sup_{\mathcal{A}} \expect{\text{Ideal}_{\adv}^{\ \leakm, g}(n)} \label{thm-equiv-1} \\
= & \mathbb{E}_{\leakm} \left[ \max_{w \in \W} \mathbb{E}_{\pi} \left[ g(w, (\db, \key), \leak \mid \leak \right] \right] \label{thm-equiv-2} \\
= &  \mathbb{E}_{\Y} \left[ \max_{w \in \W} \mathbb{E}_{\pi} \left[ g(w, \X, y) \mid y \right] \right] \\
= &  \sum_{y \in \Y} \prob{\Y = y} \max_{w \in \W} \sum_{x \in \X} \prob{\X = x \mid \Y = y} g(w, x, y) \\
= & \sum_{y \in \Y} \max_{w \in \W} \sum_{x \in \X} \prob{\X = x, \Y = y} g(w, x, y) \\
= & \sum_{y \in \Y} \max_{w \in \W} \sum_{x \in \X} \pi [x] \channelm[x, y] g(w, x, y) \\
= & EV_g(\pi, \channelm).
\end{align}

In the proof, equation \ref{thm-equiv-1} is just writing out the adversary explicitly. Equation \ref{thm-equiv-2} uses the fact that for any given leakage, there is a deterministic guess that maximises the conditional expectation and the best adversary overall does this for any leakage $\leak$ he sees. The next few lines of the proof are just re-writing the expectation into algebraic form and re-arranging the terms.
\end{proof}


We can use the theorem above to draw some immediate conclusion for the real game.
\begin{proposition}[Real game is equivalent to an extended posterior g-vulnerability]
	Let $\pi$ be the prior distribution of databases and keys. Let $\X = \DB \times \Key$. Let $\Y = \EDB$. Let $\channel_{\mathcal{M}}$ be the channel matrix from $\X$ to $\Y$. Let $g: \W \times \X \times \Y \rightarrow [0,1]$. Then
	\begin{equation}
	\sup_{\pi \in \text{Dist}} \ \sup_{\mathcal{A}} \advantage_{\mathcal{A}, \pi, g}^{\text{Real}}(n) = EV_g(\pi, \channel_\mathcal{M}).
	\end{equation}
	where $Dist$ is the set of valid prior for the database.
\end{proposition}


\begin{proof}
	Let $\leakm$ in the ideal experiment be the encryption function $\enc(\cdot)$ then the idea game is exactly the real game. The result follows immediately.
\end{proof}




\subsection{Bound the Advantage in the Real World using Advantage in the Idealised World}
It would not make sense to look at the advantage in the idealised world if it has no connection to the advantage in the real world. In this subsection, we prove that by picking appropriate gain function in the idealised world, we can use the advantage in the idealised world to bound that in the real world.


\begin{theorem}
	Let $\pi$ be the prior distribution of databases and keys. Let $\X = \DB \times \Key$. Let $\Y_{\text{Real}} = \EDB$. Let $\channel_{\mathcal{M}}$ be the channel matrix from $\X$ to $\Y_{\text{Real}}$. Let $g_{\text{Real}}: \W \times \X \times \Y_{\text{Real}} \rightarrow [0,1]$.
	
	Let $\leakm$ be a valid leakage function and $\simulator$ an simulator associated to $\leakm$. Let $\Y_{\text{Ideal}} = \{\leakm(\secparam, \key, \db) \mid \key \in \Key, \db \in \DB \}$. Let $\channelm$ be the channel matrix from $\X$ to $\Y_{\text{Ideal}}$. Let $g_{\text{Ideal}}: \W \times \X \times \Y_{\text{Ideal}} \rightarrow [0,1]$ such that $g_{\text{Ideal}}(w, x, y) = g_{\text{Real}}(w, x, \simulator(y))$. Then
	
	\begin{equation}
		EV_{g_{\text{Real}}}(\pi, \channelm) \leq EV_{g_{\text{Ideal}}}(\pi, \channel_\mathcal{M})
	\end{equation}
	with overwhelming probability.
\end{theorem}


\begin{proof}
	The proof takes two steps. We will first relate the extended g-vulnerability in the idealised world to some other extended g-vulnerability. We then argue that the game related to the extended g-vulnerability we found is indistinguishable from that of the real world. Therefore, concluding the desired inequality.
	
	We begin by re-writing extended g-vulnerability in the idealised world in the following way:
	\begin{align}
	  &	EV_{g_{\text{Ideal}}}(\pi, \channel_\mathcal{M}) \\
	= & \sum_{y \in \Y_{\text{Ideal}}} \prob{y} \max_{w \in \W} \sum_{x \in \X} \prob{x \mid y} g_{\text{Ideal}}(w, x, y) \\
	= & \sum_{y \in \Y_{\text{Ideal}}} \prob{y} \max_{w \in \W} \sum_{x \in \X} \prob{x \mid y} g_{\text{Real}}(w, x, \simulator(y)) \\
	= & \sum_{\simulator(y) \in \simulator(\Y_{\text{Ideal}})} \sum_{y \in {\Y_{\text{Ideal}}}} \prob{\simulator(y)} \prob{y \mid \simulator(y)} \max_{w \in \W} \sum_{x \in \X} \prob{x \mid y} g_{\text{Real}}(w, x, \simulator(y)) \label{real-ideal-bound eq 1} \\
	\geq & \sum_{\simulator(y) \in \simulator(\Y_{\text{Ideal}})}  \prob{\simulator(y)} \max_{w \in \W} \sum_{x \in \X} \sum_{y \in {\Y_{\text{Ideal}}}} \prob{x \mid y} \prob{y \mid \simulator(y)} g_{\text{Real}}(w, x, \simulator(y)) \label{real-idea-bound eq 2} \\
	= & \sum_{\simulator(y) \in \simulator(\Y_{\text{Ideal}})}  \prob{\simulator(y)} \max_{w \in \W} \sum_{x \in \X} \sum_{y \in {\Y_{\text{Ideal}}}} \prob{x, y \mid \simulator(y)} g_{\text{Real}}(w, x, \simulator(y)) \label{real-idea-bound eq 3} \\
	= & \sum_{\simulator(y) \in \simulator(\Y_{\text{Ideal}})}  \prob{\simulator(y)} \max_{w \in \W} \sum_{x \in \X} \prob{x \mid \simulator(y)} g_{\text{Real}}(w, x, \simulator(y)). \label{real-idea-bound eq 4}
	\end{align}
	To go from equation \ref{real-ideal-bound eq 1} to equation \ref{real-idea-bound eq 2}, we used Jensen's inequality. To arrive at equation \ref{real-idea-bound eq 3}, we use the fact that $\X \rightarrow \Y_{\text{Ideal}} \rightarrow \simulator(\Y_{\text{Ideal}})$ is a Markov chain. Finally, we get equation \ref{real-idea-bound eq 4} due to law of total probability.
	
	We observe that equation \ref{real-idea-bound eq 4} is equivalent to the following game:
	\begin{pchstack}[center]
		\procedure{Simulated$_{\adv}^{\ \simulator \circ \leakm, g_{\text{Real}}}(n)$}{%
			\pcln \key \sample \kgen(\secparam) \\
			\pcln \db  \gets \mathcal{A}_0(\secparam) \\
			\pcln \edb \gets \simulator(\leakm(\secparam, \key, \db)) \\
			\pcln w \gets \mathcal{A}_1(\secparam, \edb) \\
			\pcln \pcreturn g_{\text{Real}}(w, (\db, \key), \edb)
		}
	\end{pchstack}
	But this game is indistinguishable from the real game as $\simulator$ is a simulator that makes $\simulator \circ \leakm(\cdot)$ indistinguishable from $\enc(\cdot)$ by definition. Therefore, we conclude that
	\begin{equation}
		EV_{g_{\text{Real}}}(\pi, \channelm) = \sum_{\simulator(y) \in \simulator(\Y_{\text{Ideal}})}  \prob{\simulator(y)} \max_{w \in \W} \sum_{x \in \X} \prob{x \mid \simulator(y)} g_{\text{Real}}(w, x, \simulator(y))
	\end{equation}
	with overwhelming probability. Therefore, we conclude
	\begin{equation}
		EV_{g_{\text{Real}}}(\pi, \channelm) \leq EV_{g_{\text{Ideal}}}(\pi, \channel_\mathcal{M})
	\end{equation}
	as desired.
\end{proof}




\subsection{Bounding Extended g-vulnerability using Extended g-vulnerability on Sub-channels}
In this subsection, we highlight how to use extended g-vulnerability on sub-channels to bound extended g-vulnerability of some channel. It is well-known from information theory that if $\X \rightarrow \Y \rightarrow \Z$ is a Markov chain, then $I(\X;\Y) \geq I(\X;\Z)$, where $I(\cdot)$ is the mutual information. Similar result has been shown for g-leakage in \cite{6266165, 10.1007/978-3-642-54792-8_5, 7536368} for gain functions of the form $g: \W \times \X \rightarrow [0,1]$. However, it also holds for mutual information that $I(\Y;\Z) \geq I(\X;\Z)$ but there is no corresponding result for g-vulnerability in the literature. We show that it is possible to obtain a similar result with our definition of extended g-vulnerability. We then extend our result to a channel consisting of more than two sub-channels.


\begin{theorem} \label{thm DPI 1}
	Let $\X \rightarrow \Y \rightarrow \Z$ be a Markov chain. Let $\pi$ be the prior distribution on $\X$. Let $\channel_{\X, \Y}$ be the channel matrix between $\X$ and $\Y$. Let $\channel_{\X,\Z}$ be the channel matrix between $\X$ and $\Z$. Let $\W$ be the set of allowed guesses. Let $g_{\X,\Y}: \W \times \X \times \Y \rightarrow [0,1]$ be a gain function on sub-channel $\X \rightarrow \Y$, and $g^{*}: \W \times \X \times \Z \rightarrow [0,1]$ be a gain function on the full channel. If
	\begin{equation} \label{thm DPI 1 condition}
		g^{*}(w, x, z) \leq \sum_{y \in \Y} \prob{y \mid x, z} g_{\X, \Y}(w, x, y)
	\end{equation}
	for all $w \in \W, x \in \X,$ and $z \in \Z$, then
	\begin{equation*}
		EV_{g^{*}}(\pi, \channel_{\X,\Z}) \leq EV_{g_{\X,\Y}}(\pi, \channel_{\X,\Y}).
	\end{equation*}
\end{theorem}


% The proofs should probably go to appendix
\begin{proof}
	The proof is no more than just manipulating the probabilities.
	\begin{align*}
	  &	EV_{g_{\X,\Y}}(\pi, \channel_{\X,\Y}) \\
	= & \sum_{y \in \Y} \prob{y} \max_{w \in \W} \sum_{x \in \X} \prob{x \mid y} g_{\X,\Y}(w, x, y) \\
  	= & \sum_{z \in \Z} \sum_{y \in \Y} \prob{z} \prob{y \mid z} \max_{w \in \W} \sum_{x \in \X} \prob{x \mid y} g_{\X,\Y}(w, x, y) \\
  	\geq & \sum_{z \in \Z} \prob{z} \max_{w \in \W} \sum_{x \in \X} \sum_{y \in \Y} \prob{x \mid y} \prob{y \mid z} g_{\X,\Y}(w, x, y) \\
  	= & \sum_{z \in \Z} \prob{z} \max_{w \in \W} \sum_{x \in \X} \sum_{y \in \Y} \prob{x, y \mid z} g_{\X,\Y}(w, x, y) \\
  	= & \sum_{z \in \Z} \prob{z} \max_{w \in \W} \sum_{x \in \X} \prob{x \mid z} \sum_{y \in \Y} \prob{y \mid x, z} g_{\X,\Y}(w, x, y) \\
  	\geq & \sum_{z \in \Z} \prob{z} \max_{w \in \W} \sum_{x \in \X} \prob{x \mid z} g^{*}(w, x, z) \\
  	= & EV_{g^{*}}(\pi, \channel_{\X,\Z}).
	\end{align*}
\end{proof}


\begin{corollary} \label{thm DPI 2}
	Let $\X \rightarrow \Y \rightarrow \Z$ be a Markov chain. Let $\pi$ be the prior distribution on $\X$. Let $\channel_{\X, \Y}$ be the channel matrix between $\X$ and $\Y$. Let $\channel_{\X,\Z}$ be the channel matrix between $\X$ and $\Z$. Let $\W$ be the set of allowed guesses. Let $g_{\X,\Y}: \W \times \X \times \Y \rightarrow [0,1]$ be a gain function on sub-channel $\X \rightarrow \Y$, and $g^{*}: \W \times \X \times \Z \rightarrow [0,1]$ be a gain function on the full channel. If there exists some function $G: \W \times \X$ such that $g^{*}(w, x, z) = g_{\X, \Y}(w, x, y) = G(w, x)$ for any $w \in \W, x \in \X, y \in \Y$ and $z \in \Z$, then
	\begin{equation*}
	EV_{g^{*}}(\pi, \channel_{\X,\Z}) \leq EV_{g_{\X,\Y}}(\pi, \channel_{\X,\Y}).
	\end{equation*}
\end{corollary}


\begin{proof}
	It suffices to verify equation \ref{thm DPI 1 condition} in theorem \ref{thm DPI 1}. We have
	\begin{align*}
	  &	\sum_{y \in \Y} \prob{y \mid x, z} g_{\X, \Y}(w, x, y) \\
	= & \sum_{y \in \Y} \prob{y \mid x, z} G(w, x) \\
	= & G(w, x) \sum_{y \in \Y} \prob{y \mid x, z} \\
	= & G(w, x) \\
	= & g^{*}(w, x, z).
	\end{align*}
	So the desired result follows.
\end{proof}


\begin{theorem} \label{thm DPI 3}
	Let $\X \rightarrow \Y \rightarrow \Z$ be a Markov chain. Let $\pi$ be the prior distribution on $\X$. Let $\channel_{\Y, \Z}$ be the channel matrix between $\Y$ and $\Z$. Let $\channel_{\X,\Z}$ be the channel matrix between $\X$ and $\Z$. Let $\W$ be the set of allowed guesses. Let $g_{\Y,\Z}: \W \times \Y \times \Z \rightarrow [0,1]$ be a gain function on sub-channel $\Y \rightarrow \Z$, and $g^{*}: \W \times \X \times \Z \rightarrow [0,1]$ be a gain function on the full channel. If
	\begin{equation} \label{thm DPI 3 condition}
	g^{*}(w, x, z) \leq \sum_{y \in \Y} \prob{y \mid x, z} g_{\Y, \Z}(w, y, z)
	\end{equation}
	for all $w \in \W, x \in \X,$ and $z \in \Z$, then
	\begin{equation*}
	EV_{g^{*}}(\pi, \channel_{\X,\Z}) \leq EV_{g_{\Y,\Z}}(\pi, \channel_{\Y,\Z}).
	\end{equation*}
\end{theorem}


\begin{proof}
	\begin{align*}
	  &	EV_{g_{\Y,\Z}}(\pi, \channel_{\Y,\Z}) \\
	= & \sum_{z \in \Z} \prob{z} \max_{w \in \W} \sum_{y \in \Y} \prob{y \mid z} g_{\Y, \Z}(w, x, y) \\
	= & \sum_{z \in \Z} \prob{z} \max_{w \in \W} \sum_{x \in \X} \sum_{y \in \Y} \prob{x, y \mid z} g_{\Y, \Z}(w, x, y) \\
	= & \sum_{z \in \Z} \prob{z} \max_{w \in \W} \sum_{x \in \X} \prob{x \mid z} \sum_{y \in \Y} \prob{y \mid x, z} g_{\Y, \Z}(w, x, y) \\
	\geq & \sum_{z \in \Z} \prob{z} \max_{w \in \W} \sum_{x \in \X} \prob{x \mid z} g^{*}(w, x, z) \\
	= & EV_{g^{*}}(\pi, \channel_{\X,\Z})
	\end{align*}
\end{proof}






